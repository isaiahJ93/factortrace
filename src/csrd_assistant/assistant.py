def run(prompt: str) -> str:
    """
    Thin wrapper that hands `prompt` to your LLM client and returns the answer.
    Keeps it framework-agnostic so tests & CLI stay lightweight.
    """
    ...
